{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PATE-MNIST.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNmLvbgBa0bjYkOf2gqRSKX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqJ48Tsz8E7C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "3353e56d-dabe-4bfe-e28d-aa8d131828bd"
      },
      "source": [
        "!pip install syft\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: syft in /usr/local/lib/python3.6/dist-packages (0.2.4)\n",
            "Requirement already satisfied: numpy~=1.18.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.18.2)\n",
            "Requirement already satisfied: tornado==4.5.3 in /usr/local/lib/python3.6/dist-packages (from syft) (4.5.3)\n",
            "Requirement already satisfied: torchvision~=0.5.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.5.0)\n",
            "Requirement already satisfied: requests~=2.22.0 in /usr/local/lib/python3.6/dist-packages (from syft) (2.22.0)\n",
            "Requirement already satisfied: websockets~=8.1.0 in /usr/local/lib/python3.6/dist-packages (from syft) (8.1)\n",
            "Requirement already satisfied: Flask~=1.1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.1)\n",
            "Requirement already satisfied: websocket-client~=0.57.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.57.0)\n",
            "Requirement already satisfied: syft-proto~=0.2.5.a1 in /usr/local/lib/python3.6/dist-packages (from syft) (0.2.5a1)\n",
            "Requirement already satisfied: torch~=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Requirement already satisfied: tblib~=1.6.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.6.0)\n",
            "Requirement already satisfied: Pillow~=6.2.2 in /usr/local/lib/python3.6/dist-packages (from syft) (6.2.2)\n",
            "Requirement already satisfied: msgpack~=1.0.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.0.0)\n",
            "Requirement already satisfied: phe~=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Requirement already satisfied: scipy~=1.4.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.1)\n",
            "Requirement already satisfied: flask-socketio~=4.2.1 in /usr/local/lib/python3.6/dist-packages (from syft) (4.2.1)\n",
            "Requirement already satisfied: lz4~=3.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (3.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision~=0.5.0->syft) (1.12.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests~=2.22.0->syft) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests~=2.22.0->syft) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests~=2.22.0->syft) (2019.11.28)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests~=2.22.0->syft) (1.24.3)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask~=1.1.1->syft) (1.0.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask~=1.1.1->syft) (2.11.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask~=1.1.1->syft) (7.1.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask~=1.1.1->syft) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.11.1 in /usr/local/lib/python3.6/dist-packages (from syft-proto~=0.2.5.a1->syft) (3.11.3)\n",
            "Requirement already satisfied: python-socketio>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from flask-socketio~=4.2.1->syft) (4.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask~=1.1.1->syft) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.11.1->syft-proto~=0.2.5.a1->syft) (46.0.0)\n",
            "Requirement already satisfied: python-engineio>=3.9.0 in /usr/local/lib/python3.6/dist-packages (from python-socketio>=4.3.0->flask-socketio~=4.2.1->syft) (3.12.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLXF1vdn8Pwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import Subset\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "#from syft.frameworks.torch.differential_privacy import pate\n",
        "import helper\n",
        "from syft.frameworks.torch.dp import pate\n",
        "\n",
        "# Switch between cpu and gpu depending on which is available for training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhyeFC_k8yfm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b3aecec-46c6-4604-bd54-635654960ee1"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EXzFIC-88D0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Application of transforms to normalize the mnist data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV-a0rdK91AM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Method to divide the mnist trainingset among the number of teachers to simulate unique datasets \n",
        "def private_data_loaders(trainset, teachers):\n",
        "  num_part = len(trainset) // teachers\n",
        "  \n",
        "  priv_loaders = []\n",
        "  for i in range(teachers):\n",
        "    indices = list(range(i * num_part, (i + 1)*num_part)) \n",
        "#     if (i == teachers - 1):\n",
        "#       indices = list(range(i * num_part, len(trainset)))\n",
        "    sub_pd = Subset(trainset, indices)\n",
        "    temp_loader = torch.utils.data.DataLoader(sub_pd, batch_size=64, shuffle=True)\n",
        "    priv_loaders.append(temp_loader)\n",
        "  return priv_loaders\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s92UmBi4-KhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Method for seperating the mnist test dataset into 2. The first one being the public database and the other one the private database\n",
        "def test_database_seperator(testset):\n",
        "  i1 = int(len(testset) * 0.9)\n",
        "  i2 = int(len(testset) * 0.1)\n",
        "  \n",
        "  ind1 = list(range(0, i1))\n",
        "  ind2 = list(range(i1, len(testset)))\n",
        "  \n",
        "  pdb = Subset(testset, ind1)\n",
        "  \n",
        "  db = Subset(testset, ind2)\n",
        "  \n",
        "  pdb_loader = torch.utils.data.DataLoader(pdb, batch_size=64, shuffle=False)\n",
        "  \n",
        "  db_loader = torch.utils.data.DataLoader(db, batch_size=64, shuffle=True)\n",
        "  return pdb_loader, db_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRWox2SV-Tqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Method for creating and training a model\n",
        "def create_train_model(classifier, loader, lr = 0.12, epoch = 100):\n",
        "  print(\"Running on \", device)\n",
        "  model = classifier()\n",
        "  optimizer = optim.SGD(model.parameters(), lr)\n",
        "  \n",
        "  criterion = nn.NLLLoss()\n",
        "  \n",
        "  model.to(device)\n",
        "  for i in range(epoch):\n",
        "    cum_loss  = 0\n",
        "    cum_perc = 0\n",
        "    for imgs, labels in loader:\n",
        "      imgs, labels = imgs.to(device), labels.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      output = model.forward(imgs)\n",
        "      loss = criterion(output, labels)\n",
        "      loss.backward()\n",
        "      cum_loss +=  loss.item()\n",
        "      optimizer.step()\n",
        "    for imgs, labels in loader:\n",
        "      imgs, labels = imgs.to(device), labels.to(device)\n",
        "      with torch.no_grad():\n",
        "        ps =  torch.exp(model.forward(imgs))\n",
        "      top_p, top_class = ps.topk(1, dim = 1)\n",
        "      prob = top_class == labels.view(*top_class.shape)\n",
        "      prob = prob.float()\n",
        "      cum_perc += prob.mean().float()\n",
        "    if (i == epoch -1):\n",
        "      print(\"The loss for {0} epoch is {1}\".format(i, cum_loss / len(loader)))\n",
        "      print(\"The percentage for {0} epoch is {1}\".format(i, cum_perc / len(loader)))  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyy0CxCV-U9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Method for running the unlabelled database through the teacher models in order to get their respective predictions for each items.\n",
        "\n",
        "def evaluate(models, loader):\n",
        "  m_labels = []\n",
        "  for model in models:\n",
        "    model_class = []\n",
        "    for imgs, labels in loader:\n",
        "      imgs = imgs.to(device)\n",
        "      with torch.no_grad():\n",
        "        ps =  torch.exp(model.forward(imgs))\n",
        "      top_p, top_class = ps.topk(1, dim = 1)\n",
        "      \n",
        "      model_class.append(np.array(top_class.cpu()).T)\n",
        "    m_label = np.hstack(model_class)\n",
        "    m_labels.append(m_label)\n",
        "  return m_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seLrQwMx-ZnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Method for creating and training the teacher models\n",
        "def train_teacher_models(loaders, lr = 0.12, epoch = 10):\n",
        "  teacher_models = []\n",
        "  for loader in loaders:\n",
        "    model = create_train_model(classifier, loader, lr, epoch)\n",
        "    teacher_models.append(model)\n",
        "  return teacher_models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Hj2gkRm-dem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Method for applying Global differential privacy to the labels predicted by the teacher models and to perform PATE analysis.\n",
        "def return_new_indices(preds, epsilon):\n",
        "  preds = preds.T\n",
        "  ind = []\n",
        "  beta = 1 / epsilon\n",
        "  for pred in preds:\n",
        "    label_count = np.bincount(pred, minlength = 10)\n",
        "    for i in range(len(label_count)):\n",
        "      label_count[i] += np.random.laplace(0, beta, 1)\n",
        "    new_labels = np.argmax(label_count)\n",
        "    ind.append(new_labels)\n",
        "\n",
        "  ind = np.array(ind)\n",
        "  return ind\n",
        "\n",
        "\n",
        "def pate_analysis(pred, ind, epsilon):\n",
        "  dde, die = pate.perform_analysis(teacher_preds = pred, indices = ind, noise_eps = epsilon, delta = 1e-5 )\n",
        "  print(\"Data dependent epsilon \", dde)\n",
        "  print(\"Data Independent epsilon \", die)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvo1-s-r-wWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Method to create a new dataloader with the new target labels and the public database\n",
        "def join_label_image(dataloader, ind):\n",
        "  img_list = []\n",
        "  for img,label in dataloader:\n",
        "    img_list.append(img)\n",
        "\n",
        "  images = np.vstack(img_list)\n",
        "\n",
        "  model_zip = list(zip(images, ind))\n",
        "  modelloader = torch.utils.data.DataLoader(model_zip, shuffle=True, batch_size=64)\n",
        "  return modelloader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97tWSvuB-0yO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Method o analyze the private database with the trained model\n",
        "def analyze_privatedata(model, loader):\n",
        "  print(\"Running on \", device)\n",
        "  model.to(device)\n",
        "  cum_perc = 0\n",
        "  for imgs, labels in loader:\n",
        "    imgs, labels = imgs.to(device), labels.to(device)\n",
        "    with torch.no_grad():\n",
        "      ps =  torch.exp(model.forward(imgs))\n",
        "    top_p, top_class = ps.topk(1, dim = 1)\n",
        "    prob = top_class == labels.view(*top_class.shape)\n",
        "    prob = prob.float()\n",
        "    cum_perc += prob.mean().float()\n",
        "  print(\"The accuracy of the differentially private model on the private dataset is {0}%\".format((cum_perc / len(loader)) * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcUZXoBY-5YC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAlAGiGR_DBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Classifier for creating the models\n",
        "class classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__() \n",
        "    self.fc1 = nn.Linear(784, 256)\n",
        "    self.fc2 = nn.Linear(256, 128)\n",
        "    self.fc3 = nn.Linear(128, 64)\n",
        "    self.fc4 = nn.Linear(64, 32)\n",
        "    self.fc5 = nn.Linear(32, 10)\n",
        "    \n",
        "    self.dropout = nn.Dropout(p = 0.2)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    x = self.dropout(F.relu(self.fc1(x)))\n",
        "    x = self.dropout(F.relu(self.fc2(x)))\n",
        "    x = self.dropout(F.relu(self.fc3(x)))\n",
        "    x = self.dropout(F.relu(self.fc4(x)))\n",
        "    x = F.log_softmax(self.fc5(x), dim = 1)   \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfYmwYNP_LpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teachers = 100\n",
        "epsilon = 0.1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT78Onpa_VDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pdb, db = test_database_seperator(mnist_testset)\n",
        "teachers_loaders = private_data_loaders(mnist_trainset, teachers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn8naVYf_WkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ae68e2e-ece8-496b-ee3b-c928853a40d4"
      },
      "source": [
        "teacher_models = train_teacher_models(teachers_loaders, lr = 0.12, epoch = 40)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.4208499014377594\n",
            "The percentage for 39 epoch is 0.8619791865348816\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.47125611305236814\n",
            "The percentage for 39 epoch is 0.8421875238418579\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.4659587472677231\n",
            "The percentage for 39 epoch is 0.8791667222976685\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.30157948434352877\n",
            "The percentage for 39 epoch is 0.7807291746139526\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.731645143032074\n",
            "The percentage for 39 epoch is 0.8536458015441895\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.3601694226264954\n",
            "The percentage for 39 epoch is 0.7677083611488342\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.4831513434648514\n",
            "The percentage for 39 epoch is 0.7786458730697632\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.668919250369072\n",
            "The percentage for 39 epoch is 0.8062500357627869\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.5323271751403809\n",
            "The percentage for 39 epoch is 0.8166667222976685\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.537857124209404\n",
            "The percentage for 39 epoch is 0.8869792222976685\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.2474541410803795\n",
            "The percentage for 39 epoch is 0.8729166984558105\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 1.29457631111145\n",
            "The percentage for 39 epoch is 0.5026041865348816\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.8015836298465728\n",
            "The percentage for 39 epoch is 0.8505207896232605\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.5301473915576935\n",
            "The percentage for 39 epoch is 0.7723958492279053\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.5417367100715638\n",
            "The percentage for 39 epoch is 0.8052083253860474\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.6978338420391083\n",
            "The percentage for 39 epoch is 0.8500000238418579\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.43057134449481965\n",
            "The percentage for 39 epoch is 0.7682291865348816\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.46464897990226744\n",
            "The percentage for 39 epoch is 0.8708333373069763\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.6353884801268578\n",
            "The percentage for 39 epoch is 0.8192707896232605\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.45193700939416886\n",
            "The percentage for 39 epoch is 0.8208333253860474\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.500572144985199\n",
            "The percentage for 39 epoch is 0.8520833253860474\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.3975393891334534\n",
            "The percentage for 39 epoch is 0.8776041865348816\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.77914377450943\n",
            "The percentage for 39 epoch is 0.3265624940395355\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.5956028312444687\n",
            "The percentage for 39 epoch is 0.8588542342185974\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.6924435555934906\n",
            "The percentage for 39 epoch is 0.6197916865348816\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.5305723905563354\n",
            "The percentage for 39 epoch is 0.5697916746139526\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.7223825275897979\n",
            "The percentage for 39 epoch is 0.6031250357627869\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.4891465961933136\n",
            "The percentage for 39 epoch is 0.8901042342185974\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.5986955761909485\n",
            "The percentage for 39 epoch is 0.5901041626930237\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.8126648485660553\n",
            "The percentage for 39 epoch is 0.7463541626930237\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.6866019144654274\n",
            "The percentage for 39 epoch is 0.9130207896232605\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.4807700335979462\n",
            "The percentage for 39 epoch is 0.703125\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.29711538553237915\n",
            "The percentage for 39 epoch is 0.9369792342185974\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.5825046241283417\n",
            "The percentage for 39 epoch is 0.8479167222976685\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.5278379529714584\n",
            "The percentage for 39 epoch is 0.8104166984558105\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.47296084463596344\n",
            "The percentage for 39 epoch is 0.8348957896232605\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.35026940554380415\n",
            "The percentage for 39 epoch is 0.9151042103767395\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.7199409186840058\n",
            "The percentage for 39 epoch is 0.6614583730697632\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.29137433469295504\n",
            "The percentage for 39 epoch is 0.8364583253860474\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.4935043677687645\n",
            "The percentage for 39 epoch is 0.6859375238418579\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.3325166940689087\n",
            "The percentage for 39 epoch is 0.8916667103767395\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.5791511625051499\n",
            "The percentage for 39 epoch is 0.862500011920929\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.5845059156417847\n",
            "The percentage for 39 epoch is 0.8083333373069763\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.603055140376091\n",
            "The percentage for 39 epoch is 0.796875\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.7122516065835953\n",
            "The percentage for 39 epoch is 0.840624988079071\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.4311484232544899\n",
            "The percentage for 39 epoch is 0.8687500357627869\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.33976333141326903\n",
            "The percentage for 39 epoch is 0.8447917103767395\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.44083402007818223\n",
            "The percentage for 39 epoch is 0.8046875\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.45847325921058657\n",
            "The percentage for 39 epoch is 0.729687511920929\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.9252829372882843\n",
            "The percentage for 39 epoch is 0.737500011920929\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.8427399516105651\n",
            "The percentage for 39 epoch is 0.8036457896232605\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.5629150331020355\n",
            "The percentage for 39 epoch is 0.6760416626930237\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.7006686627864838\n",
            "The percentage for 39 epoch is 0.7109375\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 1.1105095505714417\n",
            "The percentage for 39 epoch is 0.71875\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.4362009584903717\n",
            "The percentage for 39 epoch is 0.815625011920929\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.866010057926178\n",
            "The percentage for 39 epoch is 0.8088542222976685\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.45339614152908325\n",
            "The percentage for 39 epoch is 0.6744791865348816\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.5776640266180039\n",
            "The percentage for 39 epoch is 0.8979167342185974\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.47245540618896487\n",
            "The percentage for 39 epoch is 0.8963541984558105\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.7158312067389488\n",
            "The percentage for 39 epoch is 0.9114583134651184\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.6193608775734901\n",
            "The percentage for 39 epoch is 0.8630208373069763\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.3495025604963303\n",
            "The percentage for 39 epoch is 0.9130207896232605\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.6029542118310929\n",
            "The percentage for 39 epoch is 0.7255208492279053\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.5021932244300842\n",
            "The percentage for 39 epoch is 0.8578125238418579\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.3139765202999115\n",
            "The percentage for 39 epoch is 0.8921875357627869\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.44675098061561586\n",
            "The percentage for 39 epoch is 0.8713542222976685\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.7928249657154083\n",
            "The percentage for 39 epoch is 0.7630208730697632\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.4522157579660416\n",
            "The percentage for 39 epoch is 0.7979166507720947\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.5397343128919602\n",
            "The percentage for 39 epoch is 0.8239583373069763\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.7797307908535004\n",
            "The percentage for 39 epoch is 0.7536458373069763\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.5960483223199844\n",
            "The percentage for 39 epoch is 0.6572916507720947\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.5147929251194\n",
            "The percentage for 39 epoch is 0.809374988079071\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.4580078512430191\n",
            "The percentage for 39 epoch is 0.8583332896232605\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 1.1381221771240235\n",
            "The percentage for 39 epoch is 0.42760416865348816\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.6895232379436493\n",
            "The percentage for 39 epoch is 0.8609375357627869\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.45297768861055376\n",
            "The percentage for 39 epoch is 0.8656250238418579\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.8237813085317611\n",
            "The percentage for 39 epoch is 0.6755208373069763\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.6846808224916459\n",
            "The percentage for 39 epoch is 0.760937511920929\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.47957649230957033\n",
            "The percentage for 39 epoch is 0.753125011920929\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.38083167672157286\n",
            "The percentage for 39 epoch is 0.8203125\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.3779354363679886\n",
            "The percentage for 39 epoch is 0.9036458134651184\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.5420609414577484\n",
            "The percentage for 39 epoch is 0.8010417222976685\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.6492969393730164\n",
            "The percentage for 39 epoch is 0.8052083253860474\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.8305031001567841\n",
            "The percentage for 39 epoch is 0.6895833611488342\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.4765199780464172\n",
            "The percentage for 39 epoch is 0.8536458015441895\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.42832159996032715\n",
            "The percentage for 39 epoch is 0.8786458373069763\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.5463739097118377\n",
            "The percentage for 39 epoch is 0.8067708015441895\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.4406494587659836\n",
            "The percentage for 39 epoch is 0.8348957896232605\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.5175012350082397\n",
            "The percentage for 39 epoch is 0.8770833015441895\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.5345836222171784\n",
            "The percentage for 39 epoch is 0.7994791865348816\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.44571450650691985\n",
            "The percentage for 39 epoch is 0.8192707896232605\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.40417563617229463\n",
            "The percentage for 39 epoch is 0.8765625357627869\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.3334417551755905\n",
            "The percentage for 39 epoch is 0.8755208253860474\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.6381235361099243\n",
            "The percentage for 39 epoch is 0.8062500357627869\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.6254842102527618\n",
            "The percentage for 39 epoch is 0.542187511920929\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.4128289133310318\n",
            "The percentage for 39 epoch is 0.839062511920929\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.5939521253108978\n",
            "The percentage for 39 epoch is 0.8656250238418579\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.27522441297769545\n",
            "The percentage for 39 epoch is 0.9213542342185974\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.1098681040108204\n",
            "The percentage for 39 epoch is 0.9781250357627869\n",
            "Running on  cuda\n",
            "The loss for 39 epoch is 0.29239300489425657\n",
            "The percentage for 39 epoch is 0.9281250238418579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWWFOJVu_Zxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teachers_pred = np.array(evaluate(teacher_models, pdb))\n",
        "teachers_pred = teachers_pred.reshape(teachers, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDwTCh3K_c5X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ad1b26b8-bcc5-4977-da41-c519dacf7c09"
      },
      "source": [
        "\n",
        "indices = return_new_indices(teachers_pred, epsilon)\n",
        "pate_analysis(teachers_pred, indices, epsilon)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data dependent epsilon  176.48738214594042\n",
            "Data Independent epsilon  371.5129254649703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiHwLSt-_glf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c357ea09-5532-4a81-eacf-bf3eb76d1745"
      },
      "source": [
        "labelledloader = join_label_image(pdb, indices)\n",
        "main_model = create_train_model(classifier, labelledloader, lr = 0.06, epoch = 30)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on  cuda\n",
            "The loss for 29 epoch is 0.31846795146558304\n",
            "The percentage for 29 epoch is 0.9162677526473999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGGK0q0Y_kX5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9c1013e8-dae0-42f7-d0aa-e7036ec32894"
      },
      "source": [
        "analyze_privatedata(main_model, db)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on  cuda\n",
            "The accuracy of the differentially private model on the private dataset is 87.32421875%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSSROSGYEr9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}